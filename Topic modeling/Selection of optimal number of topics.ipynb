{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "import nltk\n",
    "\n",
    "#Use file ‘C_PigbusinessDN1.xlsx’ with the stopwords of 'farm(er)'\n",
    "exl_file = '/Users/raphael/Desktop/FaceBook Data/CleanText_Varkens++.xls'\n",
    "\n",
    "df = pd.read_excel(exl_file, sheet_name='Sheet1', nrows=486)\n",
    "print(df.shape)\n",
    "df = df.dropna(subset = ['CleanText'])\n",
    "print(df.shape)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# the vectorizer object will be used to transform text to vector form\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=5, token_pattern='\\w+|$[\\d\\.]+|\\S+')\n",
    "\n",
    "# apply transformation\n",
    "tf = vectorizer.fit_transform(df['CleanText'])\n",
    "tf = tf.toarray()\n",
    "\n",
    "# tf_feature_names tells us what word each column in the matric represents\n",
    "tf_feature_names = vectorizer.get_feature_names_out()\n",
    "print(tf_feature_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa05d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import gensim\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tmtoolkit\n",
    "from tmtoolkit.topicmod.evaluate import metric_coherence_gensim\n",
    "import numpy as np\n",
    "\n",
    "df['tokens'] = df['CleanText'].apply(lambda x: word_tokenize(x))\n",
    "PerplexityList = []\n",
    "LogLikelihoodList = []\n",
    "CoherenceList = []\n",
    "doc_tokens = df['tokens'].tolist()\n",
    "flat_tokens = [word for doc in doc_tokens for word in doc]\n",
    "flat_docs = [' '.join(doc) for doc in doc_tokens]\n",
    "tf = vectorizer.fit_transform(flat_docs)\n",
    "corpus = Sparse2Corpus(tf, documents_columns=False)\n",
    "\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[\"Topic %d words\" % (topic_idx)]= ['{}'.format(feature_names[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        topic_dict[\"Topic %d weights\" % (topic_idx)]= ['{:.1f}'.format(topic[i])\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return pd.DataFrame(topic_dict)\n",
    "\n",
    "\n",
    "for number_of_topics in range(1,40,1):\n",
    "    model = LatentDirichletAllocation(n_components=number_of_topics, random_state=0, doc_topic_prior=1/number_of_topics)\n",
    "    model.fit(tf)\n",
    "    PerplexityList.append(model.perplexity(tf))\n",
    "    #the mean accuracy on the given test data and labels\n",
    "    LogLikelihoodList.append(model.score(tf))\n",
    "    no_top_words = 10\n",
    "    CoherenceList = metric_coherence_gensim(measure='c_v', topic_word_distrib=model.components_, dtm=corpus, vocab=np.array(tf_feature_names),texts=df['tokens'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2970cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = PerplexityList\n",
    "b = LogLikelihoodList\n",
    "c = CoherenceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef4145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(range(1,40,1), a, color='green', label='Perplexity')\n",
    "ax.set_xlabel(\"# of topics\")\n",
    "ax.set_ylabel(\"Perplexity score\")\n",
    "plt.grid(True)\n",
    "#plt.savefig('/Users/raphael/Desktop/FaceBook Data/topic modellig/Topic_Varkens/Clean++/C_Perplexity_DN14.jpg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(range(1,40,1), b, color='blue', label='LogLikelihood')\n",
    "ax.set_xlabel(\"# of topics\")\n",
    "ax.set_ylabel(\"Log-likelihood score\")\n",
    "plt.grid(True)\n",
    "#plt.savefig('/Users/raphael/Desktop/FaceBook Data/topic modellig/Topic_Varkens/Clean++/C_Log_Likelihood_DN14.jpg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(range(1,40,1), c, color='blue', label='Coherence')\n",
    "ax.set_xlabel(\"# of topics\")\n",
    "ax.set_ylabel(\"Coherence score\")\n",
    "plt.grid(True)\n",
    "#plt.savefig('/Users/raphael/Desktop/FaceBook Data/topic modellig/Topic_Varkens/Clean++/C_Coherence_DN14.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
