{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer  \n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "import numpy as np \n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download the necessary nltk resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Load the data frame\n",
    "exl_file = '/Users/raphael/Desktop/FaceBook Data/Clean_Varkens.xls' # replace it with your own filepath\n",
    "df = pd.read_excel(exl_file)\n",
    "df = df.replace(np.nan,\" \",regex = True)\n",
    "\n",
    "# Define the lemmatization function\n",
    "def lemmatize_text(text):\n",
    "    # Initialize the WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Determine the part of speech of each word\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    \n",
    "    # Lemmatize each word in the text based on its part of speech\n",
    "    lem_words = []\n",
    "    for word, tag in pos_tags:\n",
    "        # Determine the WordNet part of speech for the current tag\n",
    "        if tag.startswith('J'):\n",
    "            pos = wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            pos = wordnet.VERB\n",
    "        elif tag.startswith('N'):\n",
    "            pos = wordnet.NOUN\n",
    "        elif tag.startswith('R'):\n",
    "            pos = wordnet.ADV\n",
    "        else:\n",
    "            pos = wordnet.NOUN # default to noun if we can't determine the part of speech\n",
    "        \n",
    "        # Lemmatize the word based on its part of speech\n",
    "        lem_word = lemmatizer.lemmatize(word, pos=pos)\n",
    "        lem_words.append(lem_word)\n",
    "    \n",
    "    # Join the lem_words list into a single string and return it\n",
    "    return ' '.join(lem_words)\n",
    "\n",
    "# Apply the lemmatize_text function to the intended column in the data frame\n",
    "df['CleanText'] = df['CleanText'].apply(lemmatize_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
